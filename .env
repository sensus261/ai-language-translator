# USERS PERMISSIONS
WWWGROUP=1000
WWWUSER=1000

# OLLAMA API SERVICE
OLLAMA_API_SERVICE_ENV=development
OLLAMA_API_SERVICE_DEBUG=true
OLLAMA_API_SERVICE_PORT=5001
OLLAMA_API_SERVICE_URL=http://dockerhost:${OLLAMA_API_SERVICE_PORT}
ENHANCE_PRODUCT_MODEL=aya:8b-23

# OLLAMA SERVICE PROVIDER
OLLAMA_SERVICE_PORT=11434
OLLAMA_SERVICE_URL=http://ollama:${OLLAMA_SERVICE_PORT}

# For MACOS (with Ollama installed natively - better ARM advantage)
# OLLAMA_SERVICE_URL=http://host.docker.internal:${OLLAMA_SERVICE_PORT}
# ENHANCE_PRODUCT_MODEL=mistral:7b
# OLLAMA_API_SERVICE_URL=http://host.docker.internal:${OLLAMA_API_SERVICE_PORT}

# For Linux (via the ollama rocm container - AMD GPUS)
OLLAMA_SERVICE_URL=http://ollama:${OLLAMA_SERVICE_PORT}
ENHANCE_PRODUCT_MODEL=aya:8b-23
OLLAMA_API_SERVICE_URL=http://dockerhost:${OLLAMA_API_SERVICE_PORT}
INPUT_FILE_PATH=/app/english_input.txt
OUTPUT_FILE_PATH=/app/romanian_output.txt